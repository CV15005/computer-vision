{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bizarre-slovak",
   "metadata": {},
   "source": [
    "# Сегментация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9e0aa3-aba9-465c-9dde-fe874b4bd23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pooch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comic-trial",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage\n",
    "from skimage import data, restoration, util, img_as_float, filters, color, morphology, segmentation\n",
    "from skimage.filters import threshold_otsu, try_all_threshold, threshold_niblack, threshold_sauvola, threshold_multiotsu\n",
    "\n",
    "from skimage.filters import sobel, rank\n",
    "from skimage.measure import label\n",
    "from skimage.color import label2rgb\n",
    "\n",
    "from skimage.segmentation import (chan_vese, morphological_chan_vese,\n",
    "                                  morphological_geodesic_active_contour,\n",
    "                                  inverse_gaussian_gradient,\n",
    "                                  checkerboard_level_set)\n",
    "\n",
    "from skimage.segmentation import watershed, expand_labels, flood, flood_fill\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.transform import hough_line, hough_line_peaks, probabilistic_hough_line\n",
    " \n",
    "from skimage.feature import canny\n",
    "from skimage.draw import line\n",
    "from skimage.util import img_as_ubyte\n",
    "\n",
    "from skimage.graph import RAG\n",
    "from skimage import graph\n",
    "\n",
    "from skimage.segmentation import random_walker\n",
    "from skimage.data import binary_blobs\n",
    "from skimage.exposure import rescale_intensity\n",
    "\n",
    "from skimage.morphology import erosion, dilation, opening, closing, white_tophat, black_tophat, square\n",
    "from skimage.morphology import skeletonize, convex_hull_image, medial_axis, thin\n",
    "from skimage.morphology import disk\n",
    "\n",
    "from skimage.draw import ellipse\n",
    "from skimage.measure import label, regionprops, regionprops_table\n",
    "from skimage.transform import rotate\n",
    "\n",
    "from skimage.metrics import (adapted_rand_error,\n",
    "                              variation_of_information)\n",
    "from skimage.filters import sobel\n",
    "from skimage.measure import label\n",
    "from skimage.util import img_as_float\n",
    "from skimage.feature import canny\n",
    "from skimage.morphology import remove_small_objects\n",
    "from skimage.segmentation import (morphological_geodesic_active_contour,\n",
    "                                  inverse_gaussian_gradient,\n",
    "                                  watershed,\n",
    "                                  mark_boundaries)\n",
    "\n",
    "from skimage import data, segmentation, feature, future\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from functools import partial\n",
    "\n",
    "import networkx as nx\n",
    "import imageio\n",
    "import imutils\n",
    "import cv2\n",
    "\n",
    "from matplotlib import cm\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque\n",
    "from math import sqrt, exp\n",
    "import numpy as np\n",
    "import scipy.ndimage as ndi\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boolean-coalition",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_binary(image, binary):\n",
    "    fig, axes = plt.subplots(ncols=3, figsize=(16, 4))\n",
    "    ax = axes.ravel()\n",
    "    ax[0] = plt.subplot(1, 3, 1)\n",
    "    ax[1] = plt.subplot(1, 3, 2)\n",
    "    ax[2] = plt.subplot(1, 3, 3, sharex=ax[0], sharey=ax[0])\n",
    "\n",
    "    ax[0].imshow(image, cmap=plt.cm.gray)\n",
    "    ax[0].set_title('Original')\n",
    "    ax[0].axis('off')\n",
    "\n",
    "    ax[1].hist(image.ravel(), bins=256)\n",
    "    ax[1].set_title('Histogram')\n",
    "    ax[1].axvline(thresh, color='r')\n",
    "\n",
    "    ax[2].imshow(binary, cmap=plt.cm.gray)\n",
    "    ax[2].set_title('Thresholded')\n",
    "    ax[2].axis('off')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuffed-wallpaper",
   "metadata": {},
   "source": [
    "## 1. Пороговая сегментация\n",
    "## 1.1. Базовая сегментация на основе бинаризации по глобальному яркостному порогу\n",
    "__Метод Оцу__ вычисляет «оптимальный» порог (отмечен красной линией на гистограмме ниже) путем максимизации дисперсии между двумя классами пикселей, которые разделены пороговым значением. Равным образом этот порог минимизирует внутриклассовую дисперсию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boxed-municipality",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image = data.coins()\n",
    "thresh = threshold_otsu(image)\n",
    "binary = image > thresh\n",
    "\n",
    "show_binary(image, binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smooth-parameter",
   "metadata": {},
   "source": [
    "Негативное влияние неравномерной освещенности на результат сегментации по порогу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "related-drama",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = try_all_threshold(image, figsize=(10, 8), verbose=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "female-encoding",
   "metadata": {},
   "source": [
    "## 1.2. Устранение неравномерности освещения\n",
    "__Алгоритм катящегося мяча для оценки интенсивности фона__.\n",
    "Алгоритм катящегося мяча оценивает интенсивность фона изображения в оттенках серого в случае неравномерной экспозиции. Он часто используется в биомедицинской обработке изображений и был впервые предложен Стэнли Р. Стернбергом в 1983 году. \n",
    "\n",
    "Алгоритм работает как фильтр и интуитивно понятен. Мы представляем изображение как поверхность, на которой блоки единичного размера наложены друг на друга вместо каждого пикселя. Количество блоков и, следовательно, высота поверхности определяется интенсивностью пикселя. Чтобы получить интенсивность фона в желаемом (пиксельном) положении, мы представляем погружение шара под поверхность в желаемом месте. Когда мяч полностью покрыт блоками, вершина шара определяет интенсивность фона в этой позиции. Затем мы можем катать этот шар под поверхностью, чтобы получить значения фона для всего изображения.\n",
    "\n",
    "Scikit-image реализует обобщенную версию этого алгоритма, который позволяет вам использовать произвольные формы в качестве ядра и работает с n-мерными изображениями. Это позволяет напрямую фильтровать изображения RGB или фильтровать стеки изображений по любому (или всем) пространственным измерениям."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "double-contact",
   "metadata": {},
   "outputs": [],
   "source": [
    "background = restoration.rolling_ball(image)\n",
    "image_result = image - background\n",
    "fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(16, 4))\n",
    "\n",
    "ax[0].imshow(image, cmap='gray')\n",
    "ax[0].set_title('Original image')\n",
    "ax[0].axis('off')\n",
    "\n",
    "ax[1].imshow(background, cmap='gray')\n",
    "ax[1].set_title('Background')\n",
    "ax[1].axis('off')\n",
    "\n",
    "ax[2].imshow(image_result, cmap='gray')\n",
    "ax[2].set_title('Result')\n",
    "ax[2].axis('off')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protected-visibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = threshold_otsu(image_result)\n",
    "binary = image_result > thresh\n",
    "\n",
    "show_binary(image_result, binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "communist-recruitment",
   "metadata": {},
   "source": [
    "## 1.3. Локальные методы бинаризации\n",
    "Для учета эффектов неравномерности освещенности предлагается применять специализированные методы бинаризации. __Пороги Ниблака и Саувола__ - это локальные методы определения пороговых значений, которые полезны для изображений с неоднородным фоном, особенно при распознавании текста. Вместо расчета единого глобального порога для всего изображения, несколько пороговых значений вычисляются для каждого пикселя с использованием определенных формул, которые учитывают среднее значение и стандартное отклонение локальной окрестности (определяемой окном с центром вокруг пикселя)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "needed-exclusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = data.page()\n",
    "binary_global = image > threshold_otsu(image)\n",
    "\n",
    "window_size = 25\n",
    "thresh_niblack = threshold_niblack(image, window_size=window_size, k=0.8)\n",
    "thresh_sauvola = threshold_sauvola(image, window_size=window_size)\n",
    "\n",
    "binary_niblack = image > thresh_niblack\n",
    "binary_sauvola = image > thresh_sauvola"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organic-antarctica",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.imshow(image, cmap=plt.cm.gray)\n",
    "plt.title('Original')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.title('Global Threshold')\n",
    "plt.imshow(binary_global, cmap=plt.cm.gray)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.imshow(binary_niblack, cmap=plt.cm.gray)\n",
    "plt.title('Niblack Threshold')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.imshow(binary_sauvola, cmap=plt.cm.gray)\n",
    "plt.title('Sauvola Threshold')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "associate-change",
   "metadata": {},
   "source": [
    "## 1.4. Обработка с несколькими порогами\n",
    "Множественные пороги Оцу - это алгоритм пороговой обработки, который используется для разделения пикселей входного изображения на несколько различных классов, каждый из которых получается в соответствии с интенсивностью уровней серого в изображении.\n",
    "\n",
    "Multi-Otsu рассчитывает несколько пороговых значений, определяемых количеством желаемых классов. По умолчанию количество классов равно 3: для получения трех классов алгоритм возвращает два пороговых значения. Они представлены красными линиями на гистограмме ниже. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "second-surfing",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = data.camera()\n",
    "\n",
    "# Applying multi-Otsu threshold for the default value, generating\n",
    "# three classes.\n",
    "thresholds = threshold_multiotsu(image)\n",
    "\n",
    "# Using the threshold values, we generate the three regions.\n",
    "regions = np.digitize(image, bins=thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diverse-defeat",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(15, 5))\n",
    "\n",
    "# Plotting the original image.\n",
    "ax[0].imshow(image, cmap='gray')\n",
    "ax[0].set_title('Original')\n",
    "ax[0].axis('off')\n",
    "\n",
    "# Plotting the histogram and the two thresholds obtained from\n",
    "# multi-Otsu.\n",
    "ax[1].hist(image.ravel(), bins=255)\n",
    "ax[1].set_title('Histogram')\n",
    "for thresh in thresholds:\n",
    "    ax[1].axvline(thresh, color='r')\n",
    "\n",
    "# Plotting the Multi Otsu result.\n",
    "ax[2].imshow(regions, cmap='jet')\n",
    "ax[2].set_title('Multi-Otsu result')\n",
    "ax[2].axis('off')\n",
    "\n",
    "plt.subplots_adjust()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prompt-motor",
   "metadata": {},
   "outputs": [],
   "source": [
    "man_mask = np.int8(regions == 0)\n",
    "plt.imshow(man_mask, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bizarre-reminder",
   "metadata": {},
   "outputs": [],
   "source": [
    "selem = disk(6)\n",
    "opened = opening(man_mask, selem)\n",
    "\n",
    "plt.imshow(opened, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emotional-subsection",
   "metadata": {},
   "outputs": [],
   "source": [
    "opened_mask = opened == 1\n",
    "hull2 = convex_hull_image(opened_mask)\n",
    "hull_diff = img_as_float(hull2.copy())\n",
    "hull_diff[opened] = 1\n",
    "resulting = hull_diff * image\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(resulting, cmap=plt.cm.gray)\n",
    "ax.set_title('Object detection')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subtle-florist",
   "metadata": {},
   "source": [
    "## 2. Установление границ на основе минимизации энергии\n",
    "__Алгоритм сегментации Чан-Весе__ предназначен для сегментирования объектов без четко определенных границ. Этот алгоритм основан на наборах уровней, которые итеративно изменяются для минимизации энергии, которая определяется взвешенными значениями, соответствующими сумме различий интенсивности от среднего значения за пределами сегментированной области, сумме отличий от среднего значения внутри сегментированной области.\n",
    "\n",
    "Этот алгоритм был впервые предложен Тони Чаном и Люминитой Весе. Предлагаемая реализация алгоритма в библиотеке Scikit-image подходит только для изображений в градациях серого.\n",
    "\n",
    "Типичные значения лямбда1 и лямбда2 равны 1. Если «фон» сильно отличается от сегментированного объекта с точки зрения распределения (например, однородное черное изображение с фигурами разной интенсивности), то эти значения должны отличаться друг от друга.\n",
    "\n",
    "Типичные значения для mu находятся в диапазоне от 0 до 1, хотя более высокие значения могут использоваться при работе с формами с очень плохо очерченными контурами.\n",
    "\n",
    "Алгоритм также возвращает список значений, соответствующих энергии на каждой итерации. Это можно использовать для настройки различных параметров, описанных выше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confirmed-thunder",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = img_as_float(data.camera())\n",
    "cv = chan_vese(image, mu=0.25, lambda1=1, lambda2=1, tol=1e-3, max_num_iter=200,\n",
    "               dt=0.5, init_level_set=\"checkerboard\", extended_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excited-operator",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(8, 8))\n",
    "ax = axes.flatten()\n",
    "\n",
    "ax[0].imshow(image, cmap=\"gray\")\n",
    "ax[0].set_axis_off()\n",
    "ax[0].set_title(\"Original Image\", fontsize=12)\n",
    "\n",
    "ax[1].imshow(cv[0], cmap=\"gray\")\n",
    "ax[1].set_axis_off()\n",
    "title = \"Chan-Vese segmentation - {} iterations\".format(len(cv[2]))\n",
    "ax[1].set_title(title, fontsize=12)\n",
    "\n",
    "ax[2].imshow(cv[1], cmap=\"gray\")\n",
    "ax[2].set_axis_off()\n",
    "ax[2].set_title(\"Final Level Set\", fontsize=12)\n",
    "\n",
    "ax[3].plot(cv[2])\n",
    "ax[3].set_title(\"Evolution of energy over iterations\", fontsize=12)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conventional-eugene",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv[1].shape\n",
    "thresh = threshold_otsu(cv[1])\n",
    "binary = cv[1] > thresh\n",
    "\n",
    "show_binary(cv[1], binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "british-gothic",
   "metadata": {},
   "source": [
    "## 3. Сегментирование на основе контуров и границ\n",
    "## 3.1. Поиск прямых линий на основе преобразования Хафа\n",
    "Преобразование Хафа в его простейшей форме - это метод обнаружения прямых.\n",
    "\n",
    "В следующем примере мы создаем изображение с пересечением линии. Затем мы используем преобразование Хафа, чтобы исследовать пространство параметров для прямых линий, которые могут проходить через изображение.\n",
    "\n",
    "Обычно линии параметризуются как y = mx + c с градиентом m и точкой пересечения y c. Однако это означало бы, что m стремится к бесконечности для вертикальных линий. Вместо этого мы строим отрезок, перпендикулярный линии, ведущий в начало координат. Линия представлена длиной этого сегмента r и углом, который он составляет с осью x, θ.\n",
    "\n",
    "Преобразование Хафа создает массив гистограмм, представляющий пространство параметров (то есть матрицу M × N, для M различных значений радиуса и N различных значений θ). Для каждой комбинации параметров, r и θ, мы затем находим количество ненулевых пикселей во входном изображении, которые будут располагаться близко к соответствующей строке, и соответствующим образом увеличиваем массив в позиции (r, θ).\n",
    "\n",
    "Локальные максимумы на полученной гистограмме указывают параметры наиболее вероятных линий. В нашем примере максимумы наблюдаются под углом 45 и 135 градусов, что соответствует углам вектора нормали каждой линии.\n",
    "\n",
    "Другой подход - это прогрессивное вероятностное преобразование Хафа. Такой подход основан на предположении, что использование случайного подмножества точек голосования дает хорошее приближение к фактическому результату, и что линии могут быть извлечены во время процесса голосования путем обхода связанных компонентов. Это возвращает начало и конец каждого сегмента линии.\n",
    "\n",
    "Функция probabilistic_hough имеет три параметра: общий порог, который применяется к аккумулятору Хафа, минимальная длина строки и промежуток между строками, который влияет на объединение строк. В приведенном ниже примере мы находим строки длиной более 10 пикселей с зазором менее 3 пикселей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sporting-syndicate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructing test image\n",
    "image = np.zeros((200, 200))\n",
    "idx = np.arange(25, 175)\n",
    "image[idx, idx] = 255\n",
    "image[line(45, 25, 25, 175)] = 255\n",
    "image[line(25, 135, 175, 155)] = 255\n",
    "\n",
    "# Classic straight-line Hough transform\n",
    "# Set a precision of 0.5 degree.\n",
    "tested_angles = np.linspace(-np.pi / 2, np.pi / 2, 360, endpoint=False)\n",
    "h, theta, d = hough_line(image, theta=tested_angles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "average-binary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating figure 1\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 6))\n",
    "ax = axes.ravel()\n",
    "\n",
    "ax[0].imshow(image, cmap=cm.gray)\n",
    "ax[0].set_title('Input image')\n",
    "ax[0].set_axis_off()\n",
    "\n",
    "angle_step = 0.5 * np.diff(theta).mean()\n",
    "d_step = 0.5 * np.diff(d).mean()\n",
    "bounds = [np.rad2deg(theta[0] - angle_step),\n",
    "          np.rad2deg(theta[-1] + angle_step),\n",
    "          d[-1] + d_step, d[0] - d_step]\n",
    "ax[1].imshow(np.log(1 + h), extent=bounds, cmap=cm.gray, aspect=1 / 1.5)\n",
    "ax[1].set_title('Hough transform')\n",
    "ax[1].set_xlabel('Angles (degrees)')\n",
    "ax[1].set_ylabel('Distance (pixels)')\n",
    "ax[1].axis('image')\n",
    "\n",
    "ax[2].imshow(image, cmap=cm.gray)\n",
    "ax[2].set_ylim((image.shape[0], 0))\n",
    "ax[2].set_axis_off()\n",
    "ax[2].set_title('Detected lines')\n",
    "\n",
    "for _, angle, dist in zip(*hough_line_peaks(h, theta, d)):\n",
    "    (x0, y0) = dist * np.array([np.cos(angle), np.sin(angle)])\n",
    "    ax[2].axline((x0, y0), slope=np.tan(angle + np.pi/2))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resident-victim",
   "metadata": {},
   "source": [
    "Рассмотрим применение вероятностного преобразования Хафа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apparent-float",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Line finding using the Probabilistic Hough Transform\n",
    "image = data.camera()\n",
    "edges = canny(image, 2, 1, 25)\n",
    "lines = probabilistic_hough_line(edges, threshold=10, line_length=5,\n",
    "                                 line_gap=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heard-turtle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating figure 2\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5), sharex=True, sharey=True)\n",
    "ax = axes.ravel()\n",
    "\n",
    "ax[0].imshow(image, cmap=cm.gray)\n",
    "ax[0].set_title('Input image')\n",
    "\n",
    "ax[1].imshow(edges, cmap=cm.gray)\n",
    "ax[1].set_title('Canny edges')\n",
    "\n",
    "ax[2].imshow(edges * 0)\n",
    "for line in lines:\n",
    "    p0, p1 = line\n",
    "    ax[2].plot((p0[0], p1[0]), (p0[1], p1[1]))\n",
    "ax[2].set_xlim((0, image.shape[1]))\n",
    "ax[2].set_ylim((image.shape[0], 0))\n",
    "ax[2].set_title('Probabilistic Hough')\n",
    "\n",
    "for a in ax:\n",
    "    a.set_axis_off()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intermediate-mauritius",
   "metadata": {},
   "source": [
    "## 3.2. Метод морфологической обработки контуров Morphological Snakes\n",
    "Morphological Snakes - это семейство методов сегментации изображений. Их поведение аналогично поведению методов на основе активных контуров (например, «Геодезические активные контуры» или «Активные контуры без ребер»). Однако Morphological Snakes используют морфологические операторы (такие как дилатация или эрозия). Это делает данное семейство методов быстрее и численно более стабильными, чем их традиционные аналоги.\n",
    "\n",
    "В реализации Scikit-image доступны два метода Morphological Snakes: морфологические геодезические активные контуры (MorphGAC, реализованные в функции morphological_geodesic_active_contour) и морфологические активные контуры без краев (MorphACWE, реализованные в функции morphological_chan_vese).\n",
    "\n",
    "MorphGAC подходит для изображений с видимыми контурами, даже если эти контуры могут быть зашумленными или частично нечеткими. Однако требуется предварительная обработка изображения для выделения контуров. Это можно сделать с помощью функции inverse_gaussian_gradient. Качество сегментации MorphGAC во многом зависит от этого шага предварительной обработки.\n",
    "\n",
    "Напротив, MorphACWE хорошо работает, когда значения пикселей внутренней и внешней областей объекта для сегментации имеют разные средние значения. В отличие от MorphGAC, MorphACWE не требует четкого определения контуров объекта и работает с исходным изображением без какой-либо предварительной обработки. Это упрощает использование и настройку MorphACWE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regular-convertible",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_evolution_in(lst):\n",
    "    \"\"\"Returns a callback function to store the evolution of the level sets in\n",
    "    the given list.\n",
    "    \"\"\"\n",
    "\n",
    "    def _store(x):\n",
    "        lst.append(np.copy(x))\n",
    "\n",
    "    return _store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordered-album",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Morphological ACWE\n",
    "image = img_as_float(data.camera())\n",
    "\n",
    "# Initial level set\n",
    "init_ls = checkerboard_level_set(image.shape, 6)\n",
    "# List with intermediate results for plotting the evolution\n",
    "evolution = []\n",
    "callback = store_evolution_in(evolution)\n",
    "ls = morphological_chan_vese(image, 35, init_level_set=init_ls, smoothing=3,\n",
    "                             iter_callback=callback)\n",
    "\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(8, 8))\n",
    "ax = axes.flatten()\n",
    "\n",
    "ax[0].imshow(image, cmap=\"gray\")\n",
    "ax[0].set_axis_off()\n",
    "ax[0].contour(ls, [0.5], colors='r')\n",
    "ax[0].set_title(\"Morphological ACWE segmentation\", fontsize=12)\n",
    "\n",
    "ax[1].imshow(ls, cmap=\"gray\")\n",
    "ax[1].set_axis_off()\n",
    "contour = ax[1].contour(evolution[2], [0.5], colors='g')\n",
    "contour.collections[0].set_label(\"Iteration 2\")\n",
    "contour = ax[1].contour(evolution[7], [0.5], colors='y')\n",
    "contour.collections[0].set_label(\"Iteration 7\")\n",
    "contour = ax[1].contour(evolution[-1], [0.5], colors='r')\n",
    "contour.collections[0].set_label(\"Iteration 35\")\n",
    "ax[1].legend(loc=\"upper right\")\n",
    "title = \"Morphological ACWE evolution\"\n",
    "ax[1].set_title(title, fontsize=12)\n",
    "\n",
    "\n",
    "\n",
    "# Morphological GAC\n",
    "image = img_as_float(data.coins())\n",
    "gimage = inverse_gaussian_gradient(image)\n",
    "\n",
    "# Initial level set\n",
    "init_ls = np.zeros(image.shape, dtype=np.int8)\n",
    "init_ls[10:-10, 10:-10] = 1\n",
    "# List with intermediate results for plotting the evolution\n",
    "evolution = []\n",
    "callback = store_evolution_in(evolution)\n",
    "ls = morphological_geodesic_active_contour(gimage, 230, init_ls,\n",
    "                                           smoothing=1, balloon=-1,\n",
    "                                           threshold=0.69,\n",
    "                                           iter_callback=callback)\n",
    "\n",
    "ax[2].imshow(image, cmap=\"gray\")\n",
    "ax[2].set_axis_off()\n",
    "ax[2].contour(ls, [0.5], colors='r')\n",
    "ax[2].set_title(\"Morphological GAC segmentation\", fontsize=12)\n",
    "\n",
    "ax[3].imshow(ls, cmap=\"gray\")\n",
    "ax[3].set_axis_off()\n",
    "contour = ax[3].contour(evolution[0], [0.5], colors='g')\n",
    "contour.collections[0].set_label(\"Iteration 0\")\n",
    "contour = ax[3].contour(evolution[100], [0.5], colors='y')\n",
    "contour.collections[0].set_label(\"Iteration 100\")\n",
    "contour = ax[3].contour(evolution[-1], [0.5], colors='r')\n",
    "contour.collections[0].set_label(\"Iteration 230\")\n",
    "ax[3].legend(loc=\"upper right\")\n",
    "title = \"Morphological GAC evolution\"\n",
    "ax[3].set_title(title, fontsize=12)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funky-transformation",
   "metadata": {},
   "source": [
    "## 4. Сегментирование на основе областей\n",
    "## 4.1. Базовый алгоритм водоразделов\n",
    "Водораздел - это классический алгоритм, используемый для сегментации, то есть для разделения различных объектов на изображении.\n",
    "\n",
    "Начиная с определяемых пользователем маркеров, алгоритм водораздела обрабатывает значения пикселей как местную топографию (высоту). Алгоритм затопляет бассейны от маркеров до тех пор, пока бассейны, относящиеся к разным маркерам, не встретятся на линиях водоразделов. Во многих случаях маркеры выбираются в качестве локальных минимумов изображения.\n",
    "\n",
    "В приведенном ниже примере необходимо разделить два перекрывающихся круга. Для этого вычисляется изображение, представляющее собой расстояние до фона. Максимумы этого расстояния выбраны в качестве маркеров, и затопление бассейнов от таких маркеров разделяет два круга вдоль линии водораздела."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handy-shirt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate an initial image with two overlapping circles\n",
    "x, y = np.indices((80, 80))\n",
    "x1, y1, x2, y2 = 28, 28, 44, 52\n",
    "r1, r2 = 16, 20\n",
    "mask_circle1 = (x - x1)**2 + (y - y1)**2 < r1**2\n",
    "mask_circle2 = (x - x2)**2 + (y - y2)**2 < r2**2\n",
    "image = np.logical_or(mask_circle1, mask_circle2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concerned-bunch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the markers as local maxima of the distance to the background\n",
    "distance = ndi.distance_transform_edt(image)\n",
    "coords = peak_local_max(distance, footprint=np.ones((3, 3)), labels=image)\n",
    "mask = np.zeros(distance.shape, dtype=bool)\n",
    "mask[tuple(coords.T)] = True\n",
    "markers, _ = ndi.label(mask)\n",
    "\n",
    "\n",
    "labels = watershed(-distance, markers, mask=image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriented-interference",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=2, figsize=(9, 3), sharex=True, sharey=True)\n",
    "ax = axes.ravel()\n",
    "\n",
    "ax[0].imshow(image, cmap=plt.cm.gray)\n",
    "ax[0].set_title('Overlapping objects')\n",
    "ax[1].imshow(labels, cmap=plt.cm.nipy_spectral)\n",
    "ax[1].set_title('Separated objects')\n",
    "\n",
    "for a in ax:\n",
    "    a.set_axis_off()\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "starting-strip",
   "metadata": {},
   "source": [
    "## 4.2. Поиск регулярных структур с помощью алгоритма компактного водораздела\n",
    "Преобразование водораздела обычно используется в качестве отправной точки для многих алгоритмов сегментации. Однако без разумного выбора маркера начала обработки алгоритм может давать очень неравномерные размеры фрагментов, с которыми может быть трудно справиться при последующем анализе.\n",
    "\n",
    "Оба алгоритма реализованы в функции skimage.morphology.watershed(). Чтобы использовать компактную форму, требуется передать в аргумент значение компактности больше 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medieval-associate",
   "metadata": {},
   "outputs": [],
   "source": [
    "coins = data.coins()\n",
    "edges = filters.sobel(coins)\n",
    "\n",
    "grid = util.regular_grid(coins.shape, n_points=468)\n",
    "\n",
    "\n",
    "seeds = np.zeros(coins.shape, dtype=int)\n",
    "seeds[grid] = np.arange(seeds[grid].size).reshape(seeds[grid].shape) + 1\n",
    "\n",
    "\n",
    "w0 = watershed(edges, seeds)\n",
    "w1 = watershed(edges, seeds, compactness=0.01)\n",
    "\n",
    "fig, (ax0, ax1) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "ax0.imshow(color.label2rgb(w0, coins, bg_label=-1))\n",
    "ax0.set_title('Classical watershed')\n",
    "\n",
    "ax1.imshow(color.label2rgb(w1, coins, bg_label=-1))\n",
    "ax1.set_title('Compact watershed')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "religious-chance",
   "metadata": {},
   "source": [
    "## 4.3. Создание расширенной области вокруг результатов сегментации по водоразделам\n",
    "При условии наличия нескольких связанных компонентов, представленных разметкой объектов, возможно расширить область локализации с помощью skimage.segmentation.expand_labels(). В отличие от skimage.morphology.dilation() этот метод не позволяет соединенным компонентам расширяться на соседние связанные компоненты с меньшим номером метки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "harmful-disney",
   "metadata": {},
   "outputs": [],
   "source": [
    "coins = data.coins()\n",
    "\n",
    "# Make segmentation using edge-detection and watershed.\n",
    "edges = sobel(coins)\n",
    "\n",
    "# Identify some background and foreground pixels from the intensity values.\n",
    "# These pixels are used as seeds for watershed.\n",
    "markers = np.zeros_like(coins)\n",
    "foreground, background = 1, 2\n",
    "markers[coins < 30.0] = background\n",
    "markers[coins > 150.0] = foreground\n",
    "\n",
    "ws = watershed(edges, markers)\n",
    "seg1 = label(ws == foreground)\n",
    "\n",
    "\n",
    "expanded = expand_labels(seg1, distance=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "harmful-optimization",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(9, 5),\n",
    "                         sharex=True, sharey=True)\n",
    "\n",
    "color1 = label2rgb(seg1, image=coins, bg_label=0)\n",
    "axes[0].imshow(color1)\n",
    "axes[0].set_title('Sobel+Watershed')\n",
    "\n",
    "color2 = label2rgb(expanded, image=coins, bg_label=0)\n",
    "axes[1].imshow(color2)\n",
    "axes[1].set_title('Expanded labels')\n",
    "\n",
    "for a in axes:\n",
    "    a.axis('off')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handled-intro",
   "metadata": {},
   "source": [
    "## 4.4. Поиск маркеров для сегментации с помощью водоразделов\n",
    "Функция peak_local_max возвращает координаты локальных пиков (максимумов) изображения. Внутренне фильтр максимума используется для поиска локальных максимумов. Эта операция расширяет исходное изображение с помощью дилатации и объединяет соседние локальные максимумы, находящиеся в пределах дилатации. Места, где исходное изображение равно расширенному изображению, возвращаются как локальные максимумы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "running-confusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "im = img_as_float(data.coins())\n",
    "\n",
    "# image_max is the dilation of im with a 20*20 structuring element\n",
    "# It is used within peak_local_max function\n",
    "image_max = ndi.maximum_filter(im, size=20, mode='constant')\n",
    "\n",
    "# Comparison between image_max and im to find the coordinates of local maxima\n",
    "coordinates = peak_local_max(im, min_distance=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "significant-composite",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display results\n",
    "fig, axes = plt.subplots(1, 3, figsize=(8, 3), sharex=True, sharey=True)\n",
    "ax = axes.ravel()\n",
    "ax[0].imshow(im, cmap=plt.cm.gray)\n",
    "ax[0].axis('off')\n",
    "ax[0].set_title('Original')\n",
    "\n",
    "ax[1].imshow(image_max, cmap=plt.cm.gray)\n",
    "ax[1].axis('off')\n",
    "ax[1].set_title('Maximum filter')\n",
    "\n",
    "ax[2].imshow(im, cmap=plt.cm.gray)\n",
    "ax[2].autoscale(False)\n",
    "ax[2].plot(coordinates[:, 1], coordinates[:, 0], 'r.')\n",
    "ax[2].axis('off')\n",
    "ax[2].set_title('Peak local max')\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disabled-broadway",
   "metadata": {},
   "source": [
    "## 4.5. Использование градиентов для получения маркеров преобразования водораздела\n",
    "Получение маркера может быть выполнено на основании областей с низким значением градиента. В градиентном изображении области с высокими значениями соответствуют граничным областям. Использование в качестве маркеров более низких значений гарантирует, что сегментированные объекты будут найдены."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blond-dance",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = img_as_ubyte(data.eagle())\n",
    "\n",
    "# denoise image\n",
    "denoised = rank.median(image, disk(2))\n",
    "\n",
    "# find continuous region (low gradient -\n",
    "# where less than 10 for this image) --> markers\n",
    "# disk(5) is used here to get a more smooth image\n",
    "markers = rank.gradient(denoised, disk(5)) < 10\n",
    "\n",
    "\n",
    "markers = ndi.label(markers)[0]\n",
    "\n",
    "\n",
    "# local gradient (disk(2) is used to keep edges thin)\n",
    "gradient = rank.gradient(denoised, disk(2))\n",
    "\n",
    "# process the watershed\n",
    "labels = watershed(gradient, markers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrong-paint",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display results\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(8, 8),\n",
    "                         sharex=True, sharey=True)\n",
    "ax = axes.ravel()\n",
    "\n",
    "ax[0].imshow(image, cmap=plt.cm.gray)\n",
    "ax[0].set_title(\"Original\")\n",
    "\n",
    "ax[1].imshow(gradient, cmap=plt.cm.nipy_spectral)\n",
    "ax[1].set_title(\"Local Gradient\")\n",
    "\n",
    "ax[2].imshow(markers, cmap=plt.cm.nipy_spectral)\n",
    "ax[2].set_title(\"Markers\")\n",
    "\n",
    "ax[3].imshow(image, cmap=plt.cm.gray)\n",
    "ax[3].imshow(labels, cmap=plt.cm.nipy_spectral, alpha=.5)\n",
    "ax[3].set_title(\"Segmented\")\n",
    "\n",
    "for a in ax:\n",
    "    a.axis('off')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "digital-masters",
   "metadata": {},
   "source": [
    "## 4.6. Метод заливки\n",
    "Заливка - это алгоритм для идентификации и / или изменения соседних значений в изображении на основе их сходства с исходной точкой.\n",
    "\n",
    "Рассмотрим простейший пример выполнения заливки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stainless-danish",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkers = data.checkerboard()\n",
    "\n",
    "# Fill a square near the middle with value 127, starting at index (76, 76)\n",
    "filled_checkers = flood_fill(checkers, (76, 76), 127)\n",
    "\n",
    "fig, ax = plt.subplots(ncols=2, figsize=(10, 5))\n",
    "\n",
    "ax[0].imshow(checkers, cmap=plt.cm.gray)\n",
    "ax[0].set_title('Original')\n",
    "\n",
    "ax[1].imshow(filled_checkers, cmap=plt.cm.gray)\n",
    "ax[1].plot(76, 76, 'wo')  # seed point\n",
    "ax[1].set_title('After flood fill')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broken-specialist",
   "metadata": {},
   "source": [
    "Поскольку стандартная заливка требует, чтобы соседние пиксели были строго одинаковыми, ее использование ограничено в реальных изображениях с цветовыми градиентами и шумом. Для того, чтобы задавать диапазон возможных значений соседних пикселей указывается специальный аргумент. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strange-while",
   "metadata": {},
   "outputs": [],
   "source": [
    "cameraman = data.camera()\n",
    "\n",
    "# Change the cameraman's coat from dark to light (255).  The seed point is\n",
    "# chosen as (155, 150)\n",
    "light_coat = flood_fill(cameraman, (155, 150), 255, tolerance=10)\n",
    "fig, ax = plt.subplots(ncols=2, figsize=(10, 5))\n",
    "\n",
    "ax[0].imshow(cameraman, cmap=plt.cm.gray)\n",
    "ax[0].set_title('Original')\n",
    "ax[0].axis('off')\n",
    "\n",
    "ax[1].imshow(light_coat, cmap=plt.cm.gray)\n",
    "ax[1].plot(150, 155, 'ro')  # seed point\n",
    "ax[1].set_title('After flood fill')\n",
    "ax[1].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlled-integer",
   "metadata": {},
   "source": [
    "Проварьируем диапазон возможных допустимых значений соседних пикселей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "connected-russell",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = []\n",
    "\n",
    "for i in range(8):\n",
    "    tol = 5 + 20 * i\n",
    "    output.append(flood_fill(cameraman, (0, 0), 255, tolerance=tol))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "split-writer",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=3, ncols=3, figsize=(12, 12))\n",
    "ax[0, 0].imshow(cameraman, cmap=plt.cm.gray)\n",
    "ax[0, 0].set_title('Original')\n",
    "ax[0, 0].axis('off')\n",
    "\n",
    "# Plot all eight different tolerances for comparison.\n",
    "for i in range(8):\n",
    "    m, n = np.unravel_index(i + 1, (3, 3))\n",
    "    ax[m, n].imshow(output[i], cmap=plt.cm.gray)\n",
    "    ax[m, n].set_title('Tolerance {0}'.format(str(5 + 20 * i)))\n",
    "    ax[m, n].axis('off')\n",
    "    ax[m, n].plot(0, 0, 'bo')  # seed point\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "killing-april",
   "metadata": {},
   "source": [
    "Доступна родственная функция flood, которая возвращает маску, получаемую по принципу заливки, исходное изображение не изменяется. Это полезно для целей сегментации и более сложных конвейеров анализа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interstate-shade",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = data.chelsea()\n",
    "cat_sobel = filters.sobel(cat[..., 0])\n",
    "cat_nose = flood(cat_sobel, (240, 265), tolerance=0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "failing-culture",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=3, figsize=(10, 10))\n",
    "\n",
    "ax[0].imshow(cat)\n",
    "ax[0].set_title('Original')\n",
    "ax[0].axis('off')\n",
    "\n",
    "ax[1].imshow(cat_sobel)\n",
    "ax[1].set_title('Sobel filtered')\n",
    "ax[1].axis('off')\n",
    "\n",
    "ax[2].imshow(cat)\n",
    "ax[2].imshow(cat_nose, cmap=plt.cm.gray, alpha=0.3)\n",
    "ax[2].plot(265, 240, 'wo')  # seed point\n",
    "ax[2].set_title('Nose segmented with `flood`')\n",
    "ax[2].axis('off')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "editorial-glucose",
   "metadata": {},
   "source": [
    "Поскольку заливка применима к одноканальным изображениям, можно преобразовать изображение в пространство HSV, чтобы заливать пиксели аналогичного оттенка."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "essential-certificate",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = data.astronaut()\n",
    "\n",
    "img_hsv = color.rgb2hsv(img)\n",
    "img_hsv_copy = np.copy(img_hsv)\n",
    "\n",
    "# flood function returns a mask of flooded pixels\n",
    "mask = flood(img_hsv[..., 0], (313, 160), tolerance=0.016)\n",
    "\n",
    "# Set pixels of mask to new value for hue channel\n",
    "img_hsv[mask, 0] = 0.5\n",
    "\n",
    "# Post-processing in order to improve the result\n",
    "# Remove white pixels from flag, using saturation channel\n",
    "mask_postprocessed = np.logical_and(mask,\n",
    "                                    img_hsv_copy[..., 1] > 0.4)\n",
    "\n",
    "# Remove thin structures with binary opening\n",
    "mask_postprocessed = morphology.binary_opening(mask_postprocessed,\n",
    "                                               np.ones((3, 3)))\n",
    "\n",
    "# Fill small holes with binary closing\n",
    "mask_postprocessed = morphology.binary_closing(\n",
    "                mask_postprocessed, morphology.disk(20))\n",
    "img_hsv_copy[mask_postprocessed, 0] = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automatic-harvest",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(8, 4))\n",
    "ax[0].imshow(color.hsv2rgb(img_hsv))\n",
    "ax[0].axis('off')\n",
    "ax[0].set_title('After flood fill')\n",
    "ax[1].imshow(color.hsv2rgb(img_hsv_copy))\n",
    "ax[1].axis('off')\n",
    "ax[1].set_title('After flood fill and post-processing')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "earlier-speech",
   "metadata": {},
   "source": [
    "## 5. Методы сегментации на основе построения суперпикселей\n",
    "Суперпиксель можно определить как группу пикселей, которые имеют общие характеристики (например, интенсивность пикселей). Суперпиксели становятся полезными во многих алгоритмах компьютерного зрения и обработки изображений, таких как сегментация изображения, семантическая маркировка, обнаружение и отслеживание объектов по следующим причинам:\n",
    "- Они несут больше информации, чем пиксели.\n",
    "- Суперпиксели имеют перцепционное значение, поскольку пиксели, принадлежащие данному суперпикселю, обладают схожими визуальными свойствами.\n",
    "- Они обеспечивают удобное и компактное представление изображений, которое может быть очень полезно для задач, требующих большого объема вычислений.\n",
    "\n",
    "## 5.1. Метод SLIС\n",
    "SLIC (Простая линейная итеративная кластеризация) является алгоритмом для генерации суперпикселей. Этот алгоритм генерирует суперпиксели путем кластеризации пикселей на основе их цветового сходства и близости в плоскости изображения. Это делается в пятимерном пространстве [labxy], где [lab] - это цветовой вектор пикселя в цветовом пространстве CIELAB, а xy - позиция пикселя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arctic-restaurant",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = data.coffee()\n",
    "\n",
    "\n",
    "\n",
    "labels1 = segmentation.slic(img, compactness=30, n_segments=400, start_label=1)\n",
    "out1 = color.label2rgb(labels1, img, kind='avg', bg_label=0)\n",
    "out1 = out1.astype(np.uint8)\n",
    "\n",
    "plt.imshow(out1)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "other-pakistan",
   "metadata": {},
   "source": [
    "## 5.2. Метод maskSLIC\n",
    "Метод maskSLIC является расширением метода SLIC для генерации суперпикселей в конкретной интересующей области. maskSLIC может решить проблемы с границами, которые влияют на метод SLIC.\n",
    "\n",
    "Чтобы проиллюстрировать эти методы сегментации, воспользуемся изображением биологической ткани с иммуногистохимическим (ИГХ) окрашиванием."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "postal-baptist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input data\n",
    "img = data.immunohistochemistry()\n",
    "\n",
    "# Compute a mask\n",
    "lum = color.rgb2gray(img)\n",
    "mask = morphology.remove_small_holes(\n",
    "    morphology.remove_small_objects(\n",
    "        lum < 0.7, 500),\n",
    "    500)\n",
    "\n",
    "mask = morphology.opening(mask, morphology.disk(3))\n",
    "\n",
    "# SLIC result\n",
    "slic = segmentation.slic(img, n_segments=200, start_label=1)\n",
    "\n",
    "# maskSLIC result\n",
    "m_slic = segmentation.slic(img, n_segments=100, mask=mask, start_label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confident-budget",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display result\n",
    "fig, ax_arr = plt.subplots(2, 2, sharex=True, sharey=True, figsize=(10, 10))\n",
    "ax1, ax2, ax3, ax4 = ax_arr.ravel()\n",
    "\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original image')\n",
    "\n",
    "ax2.imshow(mask, cmap='gray')\n",
    "ax2.set_title('Mask')\n",
    "\n",
    "ax3.imshow(segmentation.mark_boundaries(img, slic))\n",
    "ax3.contour(mask, colors='red', linewidths=1)\n",
    "ax3.set_title('SLIC')\n",
    "\n",
    "ax4.imshow(segmentation.mark_boundaries(img, m_slic))\n",
    "ax4.contour(mask, colors='red', linewidths=1)\n",
    "ax4.set_title('maskSLIC')\n",
    "\n",
    "for ax in ax_arr.ravel():\n",
    "    ax.set_axis_off()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "executive-firewall",
   "metadata": {},
   "source": [
    "## 6. Методы сегментации на основе графов (Region Adjacency Graphs)\n",
    "Пример ниже демонстрирует использование функции merge_nodes графа смежности регионов (RAG). Класс RAG представляет собой неориентированный взвешенный граф, наследуемый от класса networkx.graph. Когда новый узел формируется путем слияния двух узлов, вес всех ребер, попадающих в результирующий узел, может быть обновлен с помощью определяемой пользователем функции weight_func.\n",
    "\n",
    "По умолчанию в случае конфликта используется меньший вес ребра. В приведенном ниже примере также показано, как использовать пользовательскую функцию для выбора большего веса в графе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "micro-significance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_edge(g, src, dst, n):\n",
    "    \"\"\"Callback to handle merging nodes by choosing maximum weight.\n",
    "\n",
    "    Returns a dictionary with `\"weight\"` set as either the weight between\n",
    "    (`src`, `n`) or (`dst`, `n`) in `g` or the maximum of the two when\n",
    "    both exist.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    g : RAG\n",
    "        The graph under consideration.\n",
    "    src, dst : int\n",
    "        The vertices in `g` to be merged.\n",
    "    n : int\n",
    "        A neighbor of `src` or `dst` or both.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data : dict\n",
    "        A dict with the \"weight\" attribute set the weight between\n",
    "        (`src`, `n`) or (`dst`, `n`) in `g` or the maximum of the two when\n",
    "        both exist.\n",
    "    \"\"\"\n",
    "\n",
    "    w1 = g[n].get(src, {'weight': -np.inf})['weight']\n",
    "    w2 = g[n].get(dst, {'weight': -np.inf})['weight']\n",
    "    return {'weight': max(w1, w2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apart-february",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(g, title):\n",
    "    \"\"\"Displays a graph with the given title.\"\"\"\n",
    "    pos = nx.circular_layout(g)\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    nx.draw(g, pos)\n",
    "    nx.draw_networkx_edge_labels(g, pos, font_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuck-reputation",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = RAG()\n",
    "g.add_edge(1, 2, weight=10)\n",
    "g.add_edge(2, 3, weight=20)\n",
    "g.add_edge(3, 4, weight=30)\n",
    "g.add_edge(4, 1, weight=40)\n",
    "g.add_edge(1, 3, weight=50)\n",
    "\n",
    "# Assigning dummy labels.\n",
    "for n in g.nodes():\n",
    "    g.nodes[n]['labels'] = [n]\n",
    "\n",
    "gc = g.copy()\n",
    "display(g, \"Original Graph\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swedish-blend",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.merge_nodes(1, 3)\n",
    "display(g, \"Merged with default (min)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varied-douglas",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.merge_nodes(1, 3, weight_func=max_edge, in_place=False)\n",
    "display(gc, \"Merged with max without in_place\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breeding-ranking",
   "metadata": {},
   "source": [
    "## 6.1. Применение порога на основе графовой модели RAG\n",
    "В этом примере создается граф смежности регионов (RAG) и объединяются области, похожие по цвету. В ходе операции объединяются области с похожим средним уровнем цвета."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technical-resident",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = data.coffee()\n",
    "\n",
    "g = graph.rag_mean_color(img, labels1)\n",
    "labels2 = graph.cut_threshold(labels1, g, 29)\n",
    "out2 = color.label2rgb(labels2, img, kind='avg', bg_label=0)\n",
    "out2 = out2.astype(np.uint8)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2, sharex=True, sharey=True,\n",
    "                       figsize=(6, 8))\n",
    "\n",
    "ax[0].imshow(img)\n",
    "ax[1].imshow(out2)\n",
    "\n",
    "for a in ax:\n",
    "    a.axis('off')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "promotional-raleigh",
   "metadata": {},
   "source": [
    "## 6.2. Выделение границ областей на основе графовых моделей RAG\n",
    "Для определения границ областей с помощью графов смежности регионов используется функция rag_boundary. Функция skimage.future.graph.rag_boundary() принимает аргумент edge_map, который дает значение функции (например, краев)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advised-syntax",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = data.coffee()\n",
    "gimg = color.rgb2gray(img)\n",
    "\n",
    "labels = segmentation.slic(img, compactness=30, n_segments=400, start_label=1)\n",
    "edges = filters.sobel(gimg)\n",
    "edges_rgb = color.gray2rgb(edges)\n",
    "\n",
    "g = graph.rag_boundary(labels, edges)\n",
    "lc = graph.show_rag(labels, g, edges_rgb, img_cmap=None, edge_cmap='viridis',\n",
    "                    edge_width=1.2)\n",
    "\n",
    "plt.colorbar(lc, fraction=0.03)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excess-father",
   "metadata": {},
   "source": [
    "Для визуальной оценки качества сегментации областей с помощью RAG можно одновременно визуализировать графовые структуры на исходном изображении."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "revised-block",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = data.coffee()\n",
    "labels = segmentation.slic(img, compactness=30, n_segments=400, start_label=1)\n",
    "g = graph.rag_mean_color(img, labels)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2, sharex=True, sharey=True, figsize=(6, 8))\n",
    "\n",
    "ax[0].set_title('RAG drawn with default settings')\n",
    "lc = graph.show_rag(labels, g, img, ax=ax[0])\n",
    "# specify the fraction of the plot area that will be used to draw the colorbar\n",
    "fig.colorbar(lc, fraction=0.03, ax=ax[0])\n",
    "\n",
    "ax[1].set_title('RAG drawn with grayscale image and viridis colormap')\n",
    "lc = graph.show_rag(labels, g, img,\n",
    "                    img_cmap='gray', edge_cmap='viridis', ax=ax[1])\n",
    "fig.colorbar(lc, fraction=0.03, ax=ax[1])\n",
    "\n",
    "for a in ax:\n",
    "    a.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "russian-consumption",
   "metadata": {},
   "source": [
    "## 7. Алгоритм сегментации на основе интерактивных маркеров\n",
    "Алгоритм случайного прохождения (Random Walker Algorithm) - это алгоритм сегментации изображения, при котором пользователь может интерактивно промаркировать небольшое количество пикселей известными метками, например, «объект» и «фон».\n",
    "\n",
    "Предполагается, что каждый немаркированный пиксель высвобождает случайного блуждающего, и вычисляется вероятность того, что случайный блуждающий элемент каждого пикселя сначала достигает начального числа с каждой меткой, т. е. если пользователь помещает K начальных чисел, каждый с другой меткой, тогда необходимо вычислить для каждого пикселя вероятность того, что случайный элемент, покинувший пиксель, первым достигнет каждого начального числа. Эти вероятности можно определить аналитически, решив систему линейных уравнений. После вычисления этих вероятностей для каждого пикселя пикселю присваивается метка, для которой он, скорее всего, отправит случайного блуждающего. Изображение моделируется как граф, в котором каждый пиксель соответствует узлу, который соединен с соседними пикселями краями, а края взвешиваются, чтобы отразить сходство между пикселями. Следовательно, случайное блуждание происходит на взвешенном графе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "documentary-ghana",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate noisy synthetic data\n",
    "data_1 = skimage.img_as_float(binary_blobs(length=128, rng=1))\n",
    "sigma = 0.35\n",
    "data_1 += np.random.normal(loc=0, scale=sigma, size=data_1.shape)\n",
    "data_1 = rescale_intensity(data_1, in_range=(-sigma, 1 + sigma),\n",
    "                         out_range=(-1, 1))\n",
    "\n",
    "# The range of the binary image spans over (-1, 1).\n",
    "# We choose the hottest and the coldest pixels as markers.\n",
    "markers = np.zeros(data_1.shape, dtype=np.uint)\n",
    "markers[data_1 < -0.95] = 1\n",
    "markers[data_1 > 0.95] = 2\n",
    "\n",
    "# Run random walker algorithm\n",
    "labels = random_walker(data_1, markers, beta=10, mode='bf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "after-comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(8, 3.2),\n",
    "                                    sharex=True, sharey=True)\n",
    "ax1.imshow(data_1, cmap='gray')\n",
    "ax1.axis('off')\n",
    "ax1.set_title('Noisy data')\n",
    "ax2.imshow(markers, cmap='magma')\n",
    "ax2.axis('off')\n",
    "ax2.set_title('Markers')\n",
    "ax3.imshow(labels, cmap='gray')\n",
    "ax3.axis('off')\n",
    "ax3.set_title('Segmentation')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invisible-candy",
   "metadata": {},
   "source": [
    "## 8. Метод сегментации на основе извлечения признаков\n",
    "## 8.1. Извлечение морфометрических признаков объектов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compound-charm",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.zeros((600, 600))\n",
    "\n",
    "rr, cc = ellipse(300, 350, 100, 220)\n",
    "image[rr, cc] = 1\n",
    "\n",
    "image = rotate(image, angle=15, order=0)\n",
    "\n",
    "rr, cc = ellipse(100, 100, 60, 50)\n",
    "image[rr, cc] = 1\n",
    "\n",
    "label_img = label(image)\n",
    "regions = regionprops(label_img)\n",
    "\n",
    "plt.imshow(label_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indonesian-shade",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.imshow(image, cmap=plt.cm.gray)\n",
    "\n",
    "for props in regions:\n",
    "    y0, x0 = props.centroid\n",
    "    orientation = props.orientation\n",
    "    x1 = x0 + math.cos(orientation) * 0.5 * props.minor_axis_length\n",
    "    y1 = y0 - math.sin(orientation) * 0.5 * props.minor_axis_length\n",
    "    x2 = x0 - math.sin(orientation) * 0.5 * props.major_axis_length\n",
    "    y2 = y0 - math.cos(orientation) * 0.5 * props.major_axis_length\n",
    "\n",
    "    ax.plot((x0, x1), (y0, y1), '-r', linewidth=2.5)\n",
    "    ax.plot((x0, x2), (y0, y2), '-r', linewidth=2.5)\n",
    "    ax.plot(x0, y0, '.g', markersize=15)\n",
    "\n",
    "    minr, minc, maxr, maxc = props.bbox\n",
    "    bx = (minc, maxc, maxc, minc, minc)\n",
    "    by = (minr, minr, maxr, maxr, minr)\n",
    "    ax.plot(bx, by, '-b', linewidth=2.5)\n",
    "\n",
    "ax.axis((0, 600, 600, 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "representative-catalog",
   "metadata": {},
   "source": [
    "Мы используем skimage.measure.regionprops_table() для вычисления (выбранных) свойств для каждого региона"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divided-county",
   "metadata": {},
   "outputs": [],
   "source": [
    "props = regionprops_table(label_img, properties=('centroid',\n",
    "                                                 'orientation',\n",
    "                                                 'major_axis_length',\n",
    "                                                 'minor_axis_length'))\n",
    "pd.DataFrame(props)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "promising-interstate",
   "metadata": {},
   "source": [
    "## 8.2. Метод случайного леса для сегментации на основе локальных признаков random forests\n",
    "Сегментация на основе обучения вычисляется с использованием локальных функций на основе локальной интенсивности, краев и текстур в разных масштабах. Предоставляемая пользователем маска используется для идентификации различных областей. Пиксели маски используются для обучения классификатора случайного леса из scikit-learn. Затем неразмеченные пиксели маркируются на основе прогноза классификатора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpha-devices",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_img = data.skin()\n",
    "\n",
    "plt.imshow(full_img)\n",
    "plt.show()\n",
    "\n",
    "img = full_img[:900, :900]\n",
    "\n",
    "# Build an array of labels for training the segmentation.\n",
    "# Here we use rectangles but visualization libraries such as plotly\n",
    "# can be used to draw a mask on the image.\n",
    "training_labels = np.zeros(img.shape[:2], dtype=np.uint8)\n",
    "training_labels[:130] = 1\n",
    "training_labels[:170, :400] = 1\n",
    "training_labels[600:900, 200:650] = 2\n",
    "training_labels[330:430, 210:320] = 3\n",
    "training_labels[260:340, 60:170] = 4\n",
    "training_labels[150:200, 720:860] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "challenging-boundary",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_min = 1\n",
    "sigma_max = 16\n",
    "features_func = partial(feature.multiscale_basic_features,\n",
    "                        intensity=True, edges=False, texture=True,\n",
    "                        sigma_min=sigma_min, sigma_max=sigma_max,\n",
    "                        channel_axis=-1)\n",
    "features = features_func(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "about-poetry",
   "metadata": {},
   "outputs": [],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleasant-superior",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(features[:,:,4], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bridal-pacific",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=50, n_jobs=-1,\n",
    "                             max_depth=10, max_samples=0.05)\n",
    "clf = future.fit_segmenter(training_labels, features, clf)\n",
    "result = future.predict_segmenter(features, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerous-salmon",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, sharex=True, sharey=True, figsize=(9, 10))\n",
    "ax[0].imshow(segmentation.mark_boundaries(img, result, mode='thick'))\n",
    "ax[0].contour(training_labels)\n",
    "ax[0].set_title('Image, mask and segmentation boundaries')\n",
    "ax[1].imshow(result)\n",
    "ax[1].set_title('Segmentation')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "twelve-enzyme",
   "metadata": {},
   "source": [
    "## 8.3. Оценка важности признаков\n",
    "Ниже мы рассмотрим важность различных функций, рассчитанную с помощью scikit-learn. Характеристики интенсивности имеют гораздо большее значение, чем особенности текстуры. Может возникнуть соблазн использовать эту информацию для уменьшения количества признаков, предоставляемых классификатору, чтобы сократить время вычислений. Однако это может привести к переобучению и ухудшению результатов на границе между областями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understood-librarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(9, 4))\n",
    "l = len(clf.feature_importances_)\n",
    "\n",
    "feature_importance = (\n",
    "        clf.feature_importances_[:l//3],\n",
    "        clf.feature_importances_[l//3:2*l//3],\n",
    "        clf.feature_importances_[2*l//3:])\n",
    "\n",
    "sigmas = np.logspace(\n",
    "        np.log2(sigma_min), np.log2(sigma_max),\n",
    "        num=int(np.log2(sigma_max) - np.log2(sigma_min) + 1),\n",
    "        base=2, endpoint=True)\n",
    "\n",
    "for ch, color in zip(range(3), ['r', 'g', 'b']):\n",
    "    ax[0].plot(sigmas, feature_importance[ch][::3], 'o', color=color)\n",
    "    ax[0].set_title(\"Intensity features\")\n",
    "    ax[0].set_xlabel(\"$\\\\sigma$\")\n",
    "\n",
    "for ch, color in zip(range(3), ['r', 'g', 'b']):\n",
    "    ax[1].plot(sigmas, feature_importance[ch][1::3], 'o', color=color)\n",
    "    ax[1].plot(sigmas, feature_importance[ch][2::3], 's', color=color)\n",
    "    ax[1].set_title(\"Texture features\")\n",
    "    ax[1].set_xlabel(\"$\\\\sigma$\")\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subsequent-carpet",
   "metadata": {},
   "source": [
    "## 8.4. Применение обученной модели к новому изображению\n",
    "Далее можно применить обученный классификатор к новым объектам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olympic-lottery",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_new = full_img[:700, 900:]\n",
    "\n",
    "plt.imshow(img_new)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "features_new = features_func(img_new)\n",
    "result_new = future.predict_segmenter(features_new, clf)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, sharex=True, sharey=True, figsize=(6, 10))\n",
    "ax[0].imshow(segmentation.mark_boundaries(img_new, result_new, mode='thick'))\n",
    "ax[0].set_title('Image')\n",
    "ax[1].imshow(result_new)\n",
    "ax[1].set_title('Segmentation')\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pediatric-safety",
   "metadata": {},
   "source": [
    "## 9. Оценка качества выполнения сегментации\n",
    "Для эмпирического определения наиболее подходящего алгоритма сегментации можно использовать различные метрики. Мы будем использовать адаптированную ошибку Рэнда и вариацию информации в качестве примера показателей и посмотрим, как избыточная сегментация (разделение истинных сегментов на слишком много подсегментов) и недостаточная сегментация (объединение разных истинных сегментов в один сегмент) влияют на разные оценки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norwegian-exclusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = data.coins()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cathedral-method",
   "metadata": {},
   "source": [
    "Во-первых, мы производим априори корректную сегментацию. Для этого простого изображения мы знаем точные функции и параметры, которые позволят произвести идеальную сегментацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "willing-salvation",
   "metadata": {},
   "outputs": [],
   "source": [
    "elevation_map = sobel(image)\n",
    "markers = np.zeros_like(image)\n",
    "markers[image < 30] = 1\n",
    "markers[image > 150] = 2\n",
    "im_true = watershed(elevation_map, markers)\n",
    "im_true = ndi.label(ndi.binary_fill_holes(im_true - 1))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "silent-deadline",
   "metadata": {},
   "source": [
    "Затем мы выполняем три разных сегментации с разными характеристиками. Первый подход использует skimage.segmentation.watershed() с компактностью, которая является полезной начальной сегментацией."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demonstrated-bacon",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = sobel(image)\n",
    "im_test1 = watershed(edges, markers=468, compactness=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "israeli-press",
   "metadata": {},
   "source": [
    "В следующем подходе используется краевой фильтр Кэнни, skimage.filters.canny(). Это очень хороший детектор краев, который дает сбалансированные результаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mysterious-agreement",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = canny(image)\n",
    "fill_coins = ndi.binary_fill_holes(edges)\n",
    "im_test2 = ndi.label(remove_small_objects(fill_coins, 21))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unavailable-journey",
   "metadata": {},
   "source": [
    "Наконец, мы используем морфологические геодезические активные контуры, skimage.segmentation.morphological_geodesic_active_contour(), метод, который обычно дает хорошие результаты, но требует много времени, чтобы прийти к хорошему ответу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tired-prompt",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = img_as_float(image)\n",
    "gradient = inverse_gaussian_gradient(image)\n",
    "init_ls = np.zeros(image.shape, dtype=np.int8)\n",
    "init_ls[10:-10, 10:-10] = 1\n",
    "im_test3 = morphological_geodesic_active_contour(gradient, num_iter=100,\n",
    "                                                 init_level_set=init_ls,\n",
    "                                                 smoothing=1, balloon=-1,\n",
    "                                                 threshold=0.69)\n",
    "im_test3 = label(im_test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatty-canada",
   "metadata": {},
   "outputs": [],
   "source": [
    "method_names = ['Compact watershed', 'Canny filter',\n",
    "                'Morphological Geodesic Active Contours']\n",
    "short_method_names = ['Compact WS', 'Canny', 'GAC']\n",
    "\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "split_list = []\n",
    "merge_list = []\n",
    "\n",
    "for name, im_test in zip(method_names, [im_test1, im_test2, im_test3]):\n",
    "    error, precision, recall = adapted_rand_error(im_true, im_test)\n",
    "    splits, merges = variation_of_information(im_true, im_test)\n",
    "    split_list.append(splits)\n",
    "    merge_list.append(merges)\n",
    "    precision_list.append(precision)\n",
    "    recall_list.append(recall)\n",
    "    print(f\"\\n## Method: {name}\")\n",
    "    print(f\"Adapted Rand error: {error}\")\n",
    "    print(f\"Adapted Rand precision: {precision}\")\n",
    "    print(f\"Adapted Rand recall: {recall}\")\n",
    "    print(f\"False Splits: {splits}\")\n",
    "    print(f\"False Merges: {merges}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "differential-medicaid",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(15, 6), constrained_layout=True)\n",
    "ax = axes.ravel()\n",
    "\n",
    "ax[0].scatter(merge_list, split_list)\n",
    "for i, txt in enumerate(short_method_names):\n",
    "    ax[0].annotate(txt, (merge_list[i], split_list[i]),\n",
    "                   verticalalignment='center')\n",
    "ax[0].set_xlabel('False Merges (bits)')\n",
    "ax[0].set_ylabel('False Splits (bits)')\n",
    "ax[0].set_title('Split Variation of Information')\n",
    "\n",
    "ax[1].scatter(precision_list, recall_list)\n",
    "for i, txt in enumerate(short_method_names):\n",
    "    ax[1].annotate(txt, (precision_list[i], recall_list[i]),\n",
    "                   verticalalignment='center')\n",
    "ax[1].set_xlabel('Precision')\n",
    "ax[1].set_ylabel('Recall')\n",
    "ax[1].set_title('Adapted Rand precision vs. recall')\n",
    "ax[1].set_xlim(0, 1)\n",
    "ax[1].set_ylim(0, 1)\n",
    "\n",
    "ax[2].imshow(mark_boundaries(image, im_true))\n",
    "ax[2].set_title('True Segmentation')\n",
    "ax[2].set_axis_off()\n",
    "\n",
    "ax[3].imshow(mark_boundaries(image, im_test1))\n",
    "ax[3].set_title('Compact Watershed')\n",
    "ax[3].set_axis_off()\n",
    "\n",
    "ax[4].imshow(mark_boundaries(image, im_test2))\n",
    "ax[4].set_title('Edge Detection')\n",
    "ax[4].set_axis_off()\n",
    "\n",
    "ax[5].imshow(mark_boundaries(image, im_test3))\n",
    "ax[5].set_title('Morphological GAC')\n",
    "ax[5].set_axis_off()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520be822-1cc0-4c74-9b55-7d266836d546",
   "metadata": {},
   "source": [
    "Пример классического метода сегментации:\n",
    "https://stackoverflow.com/questions/57813137/how-to-use-watershed-segmentation-in-opencv-python"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv_env",
   "language": "python",
   "name": "cv_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
